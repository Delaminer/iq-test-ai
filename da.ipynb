{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scipy\n",
    "# %pip install opencv-contrib-python\n",
    "# Force reload of imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial import distance as dist\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n"
     ]
    }
   ],
   "source": [
    "from iq_helper import *\n",
    "from augmentations import *\n",
    "\n",
    "def get_file_path(iq_number):\n",
    "    # Convert number (1-10) to file path \"iq_images/iq{i}.png\" but with a leading zero if i < 10\n",
    "    return f\"iq_images/iq{str(iq_number).zfill(2)}.png\"\n",
    "\n",
    "def get_image(file_path):\n",
    "    original_image = cv2.imread(file_path)\n",
    "    return original_image\n",
    "\n",
    "def get_grayscale_image(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def get_contours(image, isGray = False, isBinary = False, invert = False):\n",
    "    gray = get_grayscale_image(image) if not isGray else image\n",
    "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV) if not isBinary else (0, image)\n",
    "    if invert:\n",
    "        binary = cv2.bitwise_not(binary)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # it is possible a contour is found around the border of the image, so remove it\n",
    "    threshold = 0.95\n",
    "    contours = [contour for contour in contours if cv2.contourArea(contour) / (image.shape[0] * image.shape[1]) < threshold]\n",
    "    return contours\n",
    "\n",
    "def align_images(image1, image2, same_shape = False):\n",
    "    a_contours = get_contours(image1, True, invert=True)\n",
    "    b_contours = get_contours(image2, True, invert=True)\n",
    "    # show_image(draw_contours(image1, a_contours))\n",
    "    a_contours = sorted(a_contours, key=cv2.contourArea, reverse=True)\n",
    "    b_contours = sorted(b_contours, key=cv2.contourArea, reverse=True)\n",
    "    x, y, w, h = cv2.boundingRect(a_contours[0])\n",
    "    image1 = image1[y:y+h, x:x+w]\n",
    "    x, y, w, h = cv2.boundingRect(b_contours[0])\n",
    "    image2 = image2[y:y+h, x:x+w]\n",
    "    if same_shape:\n",
    "        # Grow the smaller image to the size of the larger image\n",
    "        if image1.shape[0] > image2.shape[0]:\n",
    "            image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n",
    "        else:\n",
    "            image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "    return image1, image2\n",
    "\n",
    "def remove_background(image1, image2):\n",
    "    base = cv2.bitwise_and(image1, image2)\n",
    "    image1 = cv2.bitwise_xor(image1, base)\n",
    "    image2 = cv2.bitwise_xor(image2, base)\n",
    "    # clean up the images\n",
    "    image1 = cv2.medianBlur(image1, 5)\n",
    "    image2 = cv2.medianBlur(image2, 5)\n",
    "    return image1, image2\n",
    "\n",
    "def process_images(image1, image2, align = True, remove_bg = True):\n",
    "    # Align the images\n",
    "    if align:\n",
    "        image1, image2 = align_images(image1, image2, True)\n",
    "    # Remove the background\n",
    "    if remove_bg:\n",
    "        image1, image2 = remove_background(image1, image2)\n",
    "    else:\n",
    "        # apply a median blur to the images to remove noise\n",
    "        image1 = cv2.medianBlur(image1, 5)\n",
    "        image2 = cv2.medianBlur(image2, 5)\n",
    "    # convert them to binary images\n",
    "    image1 = force_to_binary(image1)\n",
    "    image2 = force_to_binary(image2)\n",
    "    \n",
    "    return image1, image2\n",
    "\n",
    "model = ModelTester()\n",
    "print(\"Loaded model\")\n",
    "\n",
    "# for i in range(1, 36):\n",
    "#     images, choices, answer = get_iq_question_images(i)\n",
    "#     print(f\"Got {len(choices)} choices for IQ {i}\")\n",
    "#     show_images_grid(choices)\n",
    "\n",
    "# imgs, choices, ans = get_iq_question_images(17)\n",
    "# print(ans)\n",
    "# show_images_grid(imgs)\n",
    "# show_images_grid(choices)\n",
    "# print([img.shape for img in imgs])\n",
    "# print([img.shape for img in choices])\n",
    "# img1, img2 = imgs[0], imgs[1]\n",
    "# img1, img2 = process_images(img1, img2, align=True, remove_bg=True)\n",
    "# show_images_grid([img1, img2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New approach: Use Gradient Descent or similar to learn the parameters of the augmentation.\n",
    "# We have base augmentations: Rotate, Flipping, Stretching, Cropping, Color change, and Translation. (Potential: bitwise logic like XOR)\n",
    "\n",
    "def get_angle(org, dest, partial=None):\n",
    "    # Try to find the angle that minimizes the difference between the two images\n",
    "    # We will use the sum of absolute differences as a measure of similarity\n",
    "    # We will try angles from -180 to 180 in steps of 1 degree\n",
    "    angles = range(-180, 180)\n",
    "    best_angle = None\n",
    "    best_score = float('inf')\n",
    "    if partial:\n",
    "        # use a percentage (partial) of the choices\n",
    "        angles = np.random.choice(angles, int(len(angles) * partial))\n",
    "    for angle in angles:\n",
    "        score = augmentation_score(RotateAugmentation(angle), org, dest)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_angle = angle\n",
    "    # print(f\"Best angle: {best_angle}, score: {best_score}\")\n",
    "    return best_angle, best_score\n",
    "import math\n",
    "\n",
    "def get_offset(org, dest):\n",
    "    # Try to find the offset that minimizes the difference between the two images\n",
    "    # We will use the sum of absolute differences as a measure of similarity\n",
    "    # We will try offsets from -width to width and -height to height in steps of 1 pixel\n",
    "    height, width = org.shape[:2]\n",
    "    best_offset = None\n",
    "    best_score = float('inf')\n",
    "    # Randomly sample a tenth of the possible offsets\n",
    "    offsets = [(dx, dy) for dx in range(-width, width) for dy in range(-height, height)]\n",
    "    np.random.shuffle(offsets)\n",
    "    results = {}\n",
    "    for dx, dy in offsets[:int(len(offsets) / 10)]:\n",
    "        score = augmentation_score(TranslateAugmentation(dx, dy), org, dest)\n",
    "        score = math.log(score + 1)\n",
    "        results[(dx, dy)] = score\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_offset = (dx, dy)\n",
    "    return best_offset, best_score, results\n",
    "\n",
    "def get_offset_x(org, dest):\n",
    "    # Try to find the offset that minimizes the difference between the two images\n",
    "    # We will use the sum of absolute differences as a measure of similarity\n",
    "    # We will try offsets from -width to width and -height to height in steps of 1 pixel\n",
    "    height, width = org.shape[:2]\n",
    "    best_offset = None\n",
    "    best_score = float('inf')\n",
    "    for dx in range(-width, width):\n",
    "        # translated = TranslateAugmentation(dx, 0)(org)\n",
    "        # score = np.sum(np.abs(translated - dest))\n",
    "        score = augmentation_score(TranslateAugmentation(dx, 0), org, dest)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_offset = (dx, 0)\n",
    "    return best_offset, best_score\n",
    "def get_mirror_angle(org, dest):\n",
    "    # Try to find the angle that minimizes the difference between the two images\n",
    "    # We will use the sum of absolute differences as a measure of similarity\n",
    "    # We will try angles from -180 to 180 in steps of 1 degree\n",
    "    angles = range(0, 180)\n",
    "    best_angle = None\n",
    "    best_score = float('inf')\n",
    "    for angle in angles:\n",
    "        flipped = FlipAugmentation(angle)(org)\n",
    "        score = np.sum(np.abs(flipped - dest))\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_angle = angle\n",
    "    print(f\"Best angle: {best_angle}, score: {best_score}\")\n",
    "    return best_angle, best_score\n",
    "\n",
    "def test_rotation():\n",
    "    images, _, _ = get_iq_question_images(17)\n",
    "    org, dest = images[1], images[2]\n",
    "    org_with_bg, dest_with_bg = org.copy(), dest.copy()\n",
    "    org_with_bg, dest_with_bg = process_images(org_with_bg, dest_with_bg, remove_bg=False, align=True)\n",
    "    org, dest = process_images(org, dest, remove_bg=True, align=True)\n",
    "    print(f\"Original and destination images (no background), then with background:\")\n",
    "    # show_images_grid([org, dest, org_with_bg, dest_with_bg])\n",
    "    # Need them to have the same size\n",
    "    angle, score = get_angle(org, dest)\n",
    "    angle_test = 90\n",
    "    angle_test_score = augmentation_score(RotateAugmentation(angle_test), org, dest)\n",
    "    print(f\"Best angle of {angle} with score {score}, next to tried angle of {angle_test} with score {angle_test_score}\")\n",
    "    aug_img = RotateAugmentation(angle)(org)\n",
    "    aug_test_img = RotateAugmentation(angle_test)(org)\n",
    "    # show_images_grid([aug_img, aug_test_img, RotateAugmentation(-90)(org_with_bg), RotateAugmentation(-180)(org_with_bg)])\n",
    "    print(f\"Sample translate by 10: {augmentation_score(TranslateAugmentation(10, 0), org, dest)}\")\n",
    "\n",
    "    # Try plotting the score for different angles, scores for offset x, and scores for offset y\n",
    "    angles = range(-180, 180)\n",
    "    rotation_scores = [augmentation_score(RotateAugmentation(angle), org, dest) for angle in angles]\n",
    "    plt.plot(angles, rotation_scores)\n",
    "    offset_x = range(-org.shape[1], org.shape[1])\n",
    "    offset_x_scores = [augmentation_score(TranslateAugmentation(dx, 0), org, dest) for dx in offset_x]\n",
    "    plt.plot(offset_x, offset_x_scores)\n",
    "    offset_y = range(-org.shape[0], org.shape[0])\n",
    "    offset_y_scores = [augmentation_score(TranslateAugmentation(0, dy), org, dest) for dy in offset_y]\n",
    "    plt.plot(offset_y, offset_y_scores)\n",
    "\n",
    "    plt.title(\"Augmentation Score (No background)\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Rotation\", \"Translate X\", \"Translate Y\"])\n",
    "    plt.show()\n",
    "\n",
    "    angles = range(-180, 180)\n",
    "    rotation_scores = [augmentation_score(RotateAugmentation(angle), org_with_bg, dest_with_bg) for angle in angles]\n",
    "    plt.plot(angles, rotation_scores)\n",
    "    offset_x = range(-org_with_bg.shape[1], org_with_bg.shape[1])\n",
    "    offset_x_scores = [augmentation_score(TranslateAugmentation(dx, 0), org_with_bg, dest_with_bg) for dx in offset_x]\n",
    "    plt.plot(offset_x, offset_x_scores)\n",
    "    offset_y = range(-org_with_bg.shape[0], org_with_bg.shape[0])\n",
    "    offset_y_scores = [augmentation_score(TranslateAugmentation(0, dy), org_with_bg, dest_with_bg) for dy in offset_y]\n",
    "    plt.plot(offset_y, offset_y_scores)\n",
    "\n",
    "    plt.title(\"Augmentation Score (With background)\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Rotation\", \"Translate X\", \"Translate Y\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_translation():\n",
    "    # Testing translation\n",
    "    images, _ = get_iq_question_images(4)\n",
    "    org, dest = images[0], images[1]\n",
    "    org_with_bg, dest_with_bg = org.copy(), dest.copy()\n",
    "    org_with_bg, dest_with_bg = process_images(org_with_bg, dest_with_bg, remove_bg=False, align=True)\n",
    "    org, dest = process_images(org, dest, remove_bg=True, align=True)\n",
    "    print(f\"Original and destination images (no background), then with background:\")\n",
    "    show_images_grid([org, dest, org_with_bg, dest_with_bg])\n",
    "    # Need them to have the same size\n",
    "    final_offset, score = get_offset_x(org, dest)\n",
    "    offset_test = -40\n",
    "    print(f\"Best offset of {final_offset} with image, next to tried offset_x of {offset_test}\")\n",
    "    aug_img = TranslateAugmentation(final_offset[0], final_offset[1])(org)\n",
    "    aug_test_img = TranslateAugmentation(offset_test, 0)(org)\n",
    "    show_images_grid([aug_img, aug_test_img])\n",
    "    \n",
    "    # Try plotting the score for different angles, scores for offset x, and scores for offset y\n",
    "    angles = range(-180, 180)\n",
    "    rotation_scores = [augmentation_score(RotateAugmentation(angle), org, dest) for angle in angles]\n",
    "    plt.plot(angles, rotation_scores)\n",
    "    offset_x = range(-org.shape[1], org.shape[1])\n",
    "    offset_x_scores = [augmentation_score(TranslateAugmentation(dx, 0), org, dest) for dx in offset_x]\n",
    "    plt.plot(offset_x, offset_x_scores)\n",
    "    offset_y = range(-org.shape[0], org.shape[0])\n",
    "    offset_y_scores = [augmentation_score(TranslateAugmentation(0, dy), org, dest) for dy in offset_y]\n",
    "    plt.plot(offset_y, offset_y_scores)\n",
    "\n",
    "    plt.title(\"Augmentation Score (No background)\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Rotation\", \"Translate X\", \"Translate Y\"])\n",
    "    plt.show()\n",
    "\n",
    "    angles = range(-180, 180)\n",
    "    rotation_scores = [augmentation_score(RotateAugmentation(angle), org_with_bg, dest_with_bg) for angle in angles]\n",
    "    plt.plot(angles, rotation_scores)\n",
    "    offset_x = range(-org_with_bg.shape[1], org_with_bg.shape[1])\n",
    "    offset_x_scores = [augmentation_score(TranslateAugmentation(dx, 0), org_with_bg, dest_with_bg) for dx in offset_x]\n",
    "    plt.plot(offset_x, offset_x_scores)\n",
    "    offset_y = range(-org_with_bg.shape[0], org_with_bg.shape[0])\n",
    "    offset_y_scores = [augmentation_score(TranslateAugmentation(0, dy), org_with_bg, dest_with_bg) for dy in offset_y]\n",
    "    plt.plot(offset_y, offset_y_scores)\n",
    "\n",
    "    plt.title(\"Augmentation Score (With background)\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Rotation\", \"Translate X\", \"Translate Y\"])\n",
    "    plt.show()\n",
    "\n",
    "def test_translation_xy():\n",
    "    images, _ = get_iq_question_images(4)\n",
    "    org, dest = images[3], images[4]\n",
    "    org_with_bg, dest_with_bg = org.copy(), dest.copy()\n",
    "    org_with_bg, dest_with_bg = process_images(org_with_bg, dest_with_bg, remove_bg=False, align=True)\n",
    "    org, dest = process_images(org, dest, remove_bg=True, align=True)\n",
    "    show_images_grid([org, dest, org_with_bg, dest_with_bg])\n",
    "    final_offset, score, results = get_offset(org, dest)\n",
    "    test_offset = (-40, 40)\n",
    "    print(f\"Best offset found with {final_offset} and score {score}. Trying test offset of {test_offset}\")\n",
    "    aug_img = TranslateAugmentation(final_offset[0], final_offset[1])(org)\n",
    "    aug_test_img = TranslateAugmentation(test_offset[0], test_offset[1])(org)\n",
    "    final_offset, score, results_with_bg = get_offset(org_with_bg, dest_with_bg)\n",
    "    print(f\"Best offset found with {final_offset} and score {score} (with background). Trying test offset of {test_offset}\")\n",
    "    aug_img_with_bg = TranslateAugmentation(final_offset[0], final_offset[1])(org_with_bg)\n",
    "    aug_test_img_with_bg = TranslateAugmentation(test_offset[0], test_offset[1])(org_with_bg)\n",
    "    show_images_grid([aug_img, aug_test_img, aug_img_with_bg, aug_test_img_with_bg])\n",
    "\n",
    "    # Plot the scores for the different offsets\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for offset, score in results.items():\n",
    "        x.append(offset[0])\n",
    "        y.append(offset[1])\n",
    "        z.append(score)\n",
    "    # Create heatmap\n",
    "    plt.scatter(x, y, c=z, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Augmentation Score\")\n",
    "    plt.xlabel(\"Offset X (pixels)\")\n",
    "    plt.ylabel(\"Offset Y (pixels)\")\n",
    "    plt.show()\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for offset, score in results_with_bg.items():\n",
    "        x.append(offset[0])\n",
    "        y.append(offset[1])\n",
    "        z.append(score)\n",
    "    # Create heatmap\n",
    "    plt.scatter(x, y, c=z, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Augmentation Score\")\n",
    "    plt.xlabel(\"Offset X (pixels)\")\n",
    "    plt.ylabel(\"Offset Y (pixels)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_different_augmentations():\n",
    "    data = iq_test_to_squares(get_image('iq_images/iq17.png'))\n",
    "    org = data[1]\n",
    "    dest = data[2]\n",
    "    \n",
    "    org, dest = process_images(org, dest, remove_bg=True)\n",
    "    show_image(org)\n",
    "    show_image(dest)\n",
    "    angles = range(-180, 180)\n",
    "    scores = [augmentation_score(RotateAugmentation(angle), org, dest) for angle in angles]\n",
    "    plt.title(\"Rotation score\")\n",
    "    plt.plot(angles, scores)\n",
    "    plt.xlabel(\"Angle (degrees)\")\n",
    "    plt.show()\n",
    "    offset_x = range(-org.shape[1], org.shape[1])\n",
    "    scores = [augmentation_score(TranslateAugmentation(dx, 0), org, dest) for dx in offset_x]\n",
    "    plt.title(\"Translation X score\")\n",
    "    plt.plot(offset_x, scores)\n",
    "    plt.xlabel(\"Offset (pixels)\")\n",
    "    plt.show()\n",
    "    offset_y = range(-org.shape[0], org.shape[0])\n",
    "    scores = [augmentation_score(TranslateAugmentation(0, dy), org, dest) for dy in offset_y]\n",
    "    plt.title(\"Translation Y score\")\n",
    "    plt.plot(offset_y, scores)\n",
    "    plt.xlabel(\"Offset (pixels)\")\n",
    "    plt.show()\n",
    "\n",
    "    # try translate x by 60\n",
    "    aug_img = TranslateAugmentation(60, 0)(org)\n",
    "    show_image(aug_img)\n",
    "    # try translate y by 72\n",
    "    aug_img = TranslateAugmentation(0, 72)(org)\n",
    "    show_image(aug_img)\n",
    "    # try translate y by -90\n",
    "    aug_img = TranslateAugmentation(0, -90)(org)\n",
    "    show_image(aug_img)\n",
    "    \n",
    "test_rotation()\n",
    "# test_translation()\n",
    "# test_translation_xy()\n",
    "# plot_different_augmentations()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# images, _ = get_iq_question_images(17)\n",
    "# org, dest = images[1], images[2]\n",
    "# org_with_bg, dest_with_bg = org.copy(), dest.copy()\n",
    "# org_with_bg, dest_with_bg = process_images(org_with_bg, dest_with_bg, remove_bg=False, align=True)\n",
    "# org, dest = process_images(org, dest, remove_bg=False, align=True)\n",
    "# show_images_grid([org, dest])\n",
    "# aligned_img, similarity = warp_image(org, dest)\n",
    "# print(f\"Similarity: {similarity}\")\n",
    "# show_images_grid([aligned_img, dest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_spread(org, dest, init_params, spread, partial=None):\n",
    "    best_params = init_params\n",
    "    best_score = augmentation_score(RotateTranslateAugmentation(*init_params), org, dest)\n",
    "    spread = 10\n",
    "    xrange = range(-spread, spread)\n",
    "    yrange = range(-spread, spread)\n",
    "    rrange = range(-spread, spread)\n",
    "    if partial:\n",
    "        xrange = np.random.choice(xrange, int(2 * spread * partial))\n",
    "        yrange = np.random.choice(yrange, int(2 * spread * partial))\n",
    "        rrange = np.random.choice(rrange, int(2 * spread * partial))\n",
    "\n",
    "    for dx in xrange:\n",
    "        for dy in yrange:\n",
    "            for dr in rrange:\n",
    "                new_params = (init_params[0] + dr, init_params[1] + dx, init_params[2] + dy)\n",
    "                score = augmentation_score(RotateTranslateAugmentation(*new_params), org, dest)\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_params = new_params\n",
    "    return best_params, best_score\n",
    "\n",
    "def get_rotation_translation(org, dest):\n",
    "    # Try to find the angle that minimizes the difference between the two images\n",
    "    # We will use the sum of absolute differences as a measure of similarity\n",
    "    # We will try angles from -180 to 180 in steps of 1 degree\n",
    "    angles = range(-180, 180, 10)\n",
    "    best_params = None\n",
    "    best_score = float('inf')\n",
    "    dest_center = cv2.moments((dest > 0).astype(np.uint8) * 255)\n",
    "    dest_x = int(dest_center[\"m10\"] / dest_center[\"m00\"])\n",
    "    dest_y = int(dest_center[\"m01\"] / dest_center[\"m00\"])\n",
    "    for angle in angles:\n",
    "        rotated = RotateAugmentation(angle)(org)\n",
    "        aug_center = cv2.moments((rotated > 0).astype(np.uint8) * 255)\n",
    "        aug_center_x = int(aug_center[\"m10\"] / aug_center[\"m00\"])\n",
    "        aug_center_y = int(aug_center[\"m01\"] / aug_center[\"m00\"])\n",
    "        dx = dest_x - aug_center_x\n",
    "        dy = dest_y - aug_center_y\n",
    "        score = augmentation_score(RotateTranslateAugmentation(angle, dx, dy), org, dest)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = (angle, dx, dy)\n",
    "    # find the spread on the best params\n",
    "    best_params, best_score = try_spread(org, dest, best_params, 10)\n",
    "    return best_params, best_score\n",
    "\n",
    "def get_rotation_translation_slow(org, dest):\n",
    "    init_angle, best_score = get_angle(org, dest, partial=0.3)\n",
    "    best_params = (init_angle, 0, 0)\n",
    "    tries = [best_params]\n",
    "    best_params, best_score = try_spread(org, dest, best_params, 10, partial=0.3)\n",
    "    tries.append(best_params)\n",
    "    best_params, best_score = try_spread(org, dest, best_params, 2)\n",
    "    tries.append(best_params)\n",
    "    print(tries)\n",
    "    return best_params, best_score\n",
    "\n",
    "def test_all_rotations():\n",
    "    transitions = [(0, 1), (1, 2), (3, 4), (4, 5), (6, 7)]\n",
    "    images, _, _ = get_iq_question_images(17)\n",
    "    print(\"For iq test 17, rotating dials (45, then 90 degree rotations)\")\n",
    "    for org_idx, dest_idx in transitions:\n",
    "        org, dest = images[org_idx], images[dest_idx]\n",
    "        org, dest = process_images(org, dest, remove_bg=False, align=True)\n",
    "        best_params, best_score = get_rotation_translation(org, dest)\n",
    "        print(f\"From {org_idx} to {dest_idx}, best params: {best_params}, score: {best_score}\")\n",
    "    images, _, _ = get_iq_question_images(5)\n",
    "    print(\"\\nFor iq test 5, rotating arrows (Rule: 45 each time)\")\n",
    "    for org_idx, dest_idx in transitions:\n",
    "        org, dest = images[org_idx], images[dest_idx]\n",
    "        org, dest = process_images(org, dest, remove_bg=False, align=False)\n",
    "        best_params, best_score = get_rotation_translation(org, dest)\n",
    "        print(f\"From {org_idx} to {dest_idx}, best params: {best_params}, score: {best_score}\")\n",
    "    test_sample = True\n",
    "    if test_sample:\n",
    "        org, dest = images[6], images[7]\n",
    "        org, dest = process_images(org, dest, remove_bg=False, align=False)\n",
    "        best_params, best_score = get_rotation_translation(org, dest)\n",
    "        best_angle, best_dx, best_dy = best_params\n",
    "        best_aug = RotateTranslateAugmentation(best_angle, best_dx, best_dy)(org)\n",
    "        test_augmentation_params = (45, 0, 0)\n",
    "        test_augmentation = RotateTranslateAugmentation(*test_augmentation_params)\n",
    "        test_aug = test_augmentation(org)\n",
    "        print(f\"Found best params: {best_params}, score: {best_score}\")\n",
    "        print(f\"Test params {test_augmentation_params} had score: {augmentation_score(test_augmentation, org, dest)}\")\n",
    "        show_images_grid([org, dest, get_overlap(dest, best_aug), get_overlap(dest, test_aug)])\n",
    "test_all_rotations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prediction():\n",
    "    images, choices, answer = get_iq_question_images(17)\n",
    "    # given a list of transitions in the grid, choose the best choice from choices\n",
    "    transitions = [(0, 1), (1, 2), (3, 4), (4, 5), (6, 7)]\n",
    "    params = []\n",
    "    for org_idx, dest_idx in transitions:\n",
    "        org, dest = images[org_idx], images[dest_idx]\n",
    "        org, dest = process_images(org, dest, remove_bg=False, align=False)\n",
    "        best_params, best_score = get_rotation_translation(org, dest)\n",
    "        params.append(best_params)\n",
    "    # How similar are they? If they are the same, use this rule for the next image\n",
    "    print(params)\n",
    "    avg_rotation = sum([param[0] for param in params]) / len(params)\n",
    "    # is each rotation similar?\n",
    "    use_avg_rotation = False\n",
    "    if all([abs(param[0] - avg_rotation) < 10 for param in params]):\n",
    "        # use the average rotation\n",
    "        use_avg_rotation = True\n",
    "    if use_avg_rotation:\n",
    "        print(\"Using constant rotations\")\n",
    "        # get the score of each choice\n",
    "        scores = []\n",
    "        for i, choice in enumerate(choices):\n",
    "            org, dest = process_images(images[7], choice, remove_bg=False, align=True)\n",
    "            best_params, best_score = get_rotation_translation(org, dest)\n",
    "            print(f\"Potential choice {i} has params {best_params} with score {best_score}\")\n",
    "            scores.append(abs(best_params[0] - avg_rotation))\n",
    "        print(scores)\n",
    "        # choose the choice with the lowest score\n",
    "        choice = np.argmin(scores)\n",
    "        print(f\"Chose choice {choice} with score {scores[choice]}, correct answer is {answer}\")\n",
    "    else:\n",
    "        # might be a different pattern of rotation, or something else\n",
    "        # Might be alternating rotations\n",
    "        group1 = range(0, 5, 2)\n",
    "        group2 = range(1, 5, 2)\n",
    "        rotation1 = sum([params[i][0] for i in group1]) / 3\n",
    "        all_same1 = all([abs(params[i][0] - rotation1) < 10 for i in group1])\n",
    "        rotation2 = sum([params[i][0] for i in group2]) / 2\n",
    "        all_same2 = all([abs(params[i][0] - rotation2) < 10 for i in group2])\n",
    "        print(f\"Rotations: {rotation1}, {rotation2}, {all_same1} and {all_same2}\")\n",
    "        if all_same1 and all_same2:\n",
    "            print(\"Using alternating rotations\")\n",
    "            # alternating rotations\n",
    "            scores = []\n",
    "            for choice in choices:\n",
    "                org, dest = process_images(images[7], choice, remove_bg=False, align=False)\n",
    "                best_params, best_score = get_rotation_translation(org, dest)\n",
    "                scores.append(abs(best_params[0] - rotation1))\n",
    "            print(scores)\n",
    "            # choose the choice with the lowest score\n",
    "            choice = np.argmin(scores)\n",
    "            print(f\"Chose choice {choice} with score {scores[choice]}, correct answer is {answer}\")\n",
    "        else:\n",
    "            print(\"No pattern found\")\n",
    "get_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent (or sort of like binary search?) to find the optimal angle, offset, or other parameters\n",
    "\n",
    "def gradient_descent(create_augmentation, parameter_range, org, dest, debug=False):\n",
    "    tried_x = []\n",
    "    tried_y = []\n",
    "    def score(parameter):\n",
    "        score = augmentation_score(create_augmentation(parameter), org, dest)\n",
    "        tried_x.append(parameter)\n",
    "        tried_y.append(score)\n",
    "        return score\n",
    "    start, stop = parameter_range\n",
    "    golden_ratio = (1 + 5 ** 0.5) / 2\n",
    "    max_iterations = 100\n",
    "    tolerance = 3\n",
    "    for _ in range(max_iterations):\n",
    "        if debug:\n",
    "            print(f\"Range: {start} - {stop}\")\n",
    "        range_size = stop - start\n",
    "        if range_size < tolerance:\n",
    "            break\n",
    "\n",
    "        mid1 = stop - range_size / golden_ratio\n",
    "        mid2 = start + range_size / golden_ratio\n",
    "        # these must be integers\n",
    "        mid1 = round(mid1)\n",
    "        mid2 = round(mid2)\n",
    "\n",
    "        score1 = score(mid1)\n",
    "        score2 = score(mid2)\n",
    "\n",
    "        if score1 < score2:\n",
    "            stop = mid2\n",
    "        else:\n",
    "            start = mid1\n",
    "\n",
    "    optimal_parameter = (start + stop) / 2\n",
    "    return optimal_parameter, (tried_x, tried_y)\n",
    "\n",
    "def gradient_descent_2(create_augmentation, parameter_range, org, dest, debug=False):\n",
    "    tried_x = []\n",
    "    tried_y = []\n",
    "    def score(parameter):\n",
    "        score = augmentation_score(create_augmentation(parameter), org, dest)\n",
    "        tried_x.append(parameter)\n",
    "        tried_y.append(score)\n",
    "        return score\n",
    "    def avg_score(parameter):\n",
    "        return np.mean([score(parameter + dx) for dx in [-1, 0, 1]])\n",
    "    # The idea of this is two try nearby parameters to determine the direction to go\n",
    "    start, stop = parameter_range\n",
    "    def converge(init):\n",
    "        current = init\n",
    "        max_iterations = 20\n",
    "        for _ in range(max_iterations):\n",
    "            current_score = avg_score(current)\n",
    "            nearby = [current - 10, current + 10]\n",
    "            nearby_scores = [avg_score(n) for n in nearby]\n",
    "            if current_score < nearby_scores[0] and current_score < nearby_scores[1]:\n",
    "                return current, current_score\n",
    "            if nearby_scores[0] < nearby_scores[1]:\n",
    "                current = nearby[0]\n",
    "            else:\n",
    "                current = nearby[1]\n",
    "        return current, current_score\n",
    "    # Try different random initializations\n",
    "    best_score = float('inf')\n",
    "    best_parameter = None\n",
    "    for _ in range(5):\n",
    "        init = np.random.uniform(start, stop)\n",
    "        init = round(init)\n",
    "        parameter, this_score = converge(init)\n",
    "        if this_score < best_score:\n",
    "            best_score = this_score\n",
    "            best_parameter = parameter\n",
    "    return best_parameter, (tried_x, tried_y)   \n",
    "\n",
    "# Use gradient_descent to find the best score and parameters for each type of augmentation, and choose the best\n",
    "def learn_parameters(org, dest):\n",
    "    # The augmentation could be any of the base augmentations\n",
    "    augmentations = [RotateAugmentation, lambda dx: TranslateAugmentation(dx, 0), lambda dy: TranslateAugmentation(0, dy)]\n",
    "    names = [\"Rotate\", \"Translate X\", \"Translate Y\"]\n",
    "    parameters = [(-180, 180), (-org.shape[1], org.shape[1]), (-org.shape[0], org.shape[0])]\n",
    "    best_score = float('inf')\n",
    "    best_result = None\n",
    "    for name, create_augmentation, parameter_range in zip(names, augmentations, parameters):\n",
    "        optimal_parameter, _ = gradient_descent(create_augmentation, parameter_range, org, dest)\n",
    "        optimal_parameter = round(optimal_parameter)\n",
    "        score = augmentation_score(create_augmentation(optimal_parameter), org, dest)\n",
    "        print(f\"Optimal parameter for {name}: {optimal_parameter}, score: {score}\")\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_result = (name, optimal_parameter)\n",
    "    return best_result \n",
    "\n",
    "\n",
    "def test_gradient_descent():\n",
    "    # Test first with rotation\n",
    "    data = iq_test_to_squares(get_image('iq_images/iq17.png'))\n",
    "    org = data[1]\n",
    "    dest = data[2]\n",
    "    org, dest = align_images(org, dest, True)\n",
    "    org, dest = remove_background(org, dest)\n",
    "    print(\"Original:\")\n",
    "    show_image(org)\n",
    "    print(\"Destination:\")\n",
    "    show_image(dest)\n",
    "    print(\"Trying to find the best angle\")\n",
    "    optimal_angle, (x, y) = gradient_descent(RotateAugmentation, (-180, 180), org, dest)\n",
    "    print(f\"Optimal angle: {optimal_angle}\")\n",
    "    print(f\"Tested {len(x)} datapoints\")\n",
    "    # plot the x and y tested\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "\n",
    "def test_multiple():\n",
    "    names = []\n",
    "    images = []\n",
    "    correct_translations = []\n",
    "    boxes_translating = iq_test_to_squares(get_image('iq_images/iq04.png'))\n",
    "    names.append(\"iq04 - Boxes translating\")\n",
    "    images.append(boxes_translating)\n",
    "    correct_translations.append([[\"Translate (-50, 0)\", \"Translate (-50, 0)\"],\n",
    "                                 [\"Translate (-50, -50)\", \"Translate (-50, -50)\"],\n",
    "                                 [\"Translate (0, -50)\", \"N/A\"]])\n",
    "    arrows_rotating = iq_test_to_squares(get_image('iq_images/iq10.png'))\n",
    "    names.append(\"iq10 - Arrows rotating\")\n",
    "    images.append(arrows_rotating)\n",
    "    correct_translations.append([[\"Rotate -90\", \"Rotate -90\"],\n",
    "                                 [\"Rotate -90\", \"Rotate -90\"],\n",
    "                                 [\"Rotate -90\", \"N/A\"]])\n",
    "    umbrellas_rotating = iq_test_to_squares(get_image('iq_images/iq16.png'))\n",
    "    names.append(\"iq16 - Umbrellas rotating\")\n",
    "    images.append(umbrellas_rotating)\n",
    "    correct_translations.append([[\"Rotate 90\", \"Rotate 90\"],\n",
    "                                 [\"Rotate 90\", \"Rotate 90\"],\n",
    "                                 [\"Rotate 90\", \"N/A\"]])\n",
    "    circles_rotating = iq_test_to_squares(get_image('iq_images/iq17.png'))\n",
    "    names.append(\"iq17 - Circles rotating\")\n",
    "    images.append(circles_rotating)\n",
    "    correct_translations.append([[\"Rotate 45\", \"Rotate 90\"],\n",
    "                                 [\"Rotate 45\", \"Rotate 90\"],\n",
    "                                 [\"Rotate 45\", \"N/A\"]])\n",
    "    for name, image, label in zip(names, images, correct_translations):\n",
    "        print(name)\n",
    "        print(f\"Correct labels: \\n{label}\")\n",
    "        transitions = [(0, 1), (1, 2), (3, 4), (4, 5), (6, 7)]\n",
    "        labels = [label[0][0], label[0][1], label[1][0], label[1][1], label[2][0]]\n",
    "        for l, transition in zip(labels, transitions):\n",
    "            start, end = transition\n",
    "            org = image[start]\n",
    "            dest = image[end]\n",
    "            show_image(org)\n",
    "            show_image(dest)\n",
    "            org, dest = process_images(org, dest, remove_bg=False, align=True)\n",
    "            best_result = learn_parameters(org, dest)\n",
    "            name, parameter = best_result\n",
    "            if best_result[0] == 'Translate X':\n",
    "                augmented = TranslateAugmentation(parameter, 0)(org)\n",
    "            elif best_result[0] == 'Translate Y':\n",
    "                augmented = TranslateAugmentation(0, parameter)(org)\n",
    "            else:\n",
    "                augmented = RotateAugmentation(parameter)(org)\n",
    "            print(best_result[0])\n",
    "            show_image(org)\n",
    "            show_image(dest)\n",
    "            show_image(augmented)\n",
    "            print(f\"{start}->{end}: Got {best_result}, expected [{l}]\")\n",
    "\n",
    "\n",
    "# test_gradient_descent()\n",
    "# test_multiple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQ tests are some type of rule:\n",
    "# 1. One object is moved in some way, and might have a different shading\n",
    "# 2. There are many objects, and the rule is that there are more or less in different positions\n",
    "# 3. bitwise presence of objects/things (like XOR), this is sort of like type 2 in the fact that the number of \"things\" can change\n",
    "\n",
    "# Our first goal: given the 8 images, find if this task is type 1 or type 2\n",
    "def get_rule_type(images):\n",
    "    # Type 1 sticks out because it always has the same number of objects\n",
    "    # the issue though is that it might not be the same object (in the case of a shape chase pattern)\n",
    "    # also, some type 2 patterns might have the same number of objects\n",
    "    # good examples of type 1: 10, 16, 17. 4 is also good as a translation, but the background changes across rows\n",
    "    \n",
    "    def get_num_shapes(img, display = False):\n",
    "        # Check if there is exactly one object in this\n",
    "        # if there is, then it's type 1\n",
    "        # if there is more than one, then it's type 2\n",
    "        # if there is none, then it's type 3\n",
    "        # We can check for the number of objects by checking the number of contours\n",
    "        contours = get_contours(img, False)\n",
    "        # Note that if an object is hollow, it might have two contours\n",
    "        # therefore, remove all contours that go from white to black (defines a whole in the object)\n",
    "        def black_to_white(img, contour):\n",
    "            # get random pixels inside the contour\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            x = x + w // 2\n",
    "            y = y + h // 2\n",
    "            # print(contour)\n",
    "            # scatter plot the points in the contour\n",
    "            x_values = [point[0][0] for point in contour]\n",
    "            y_values = [point[0][1] for point in contour]\n",
    "            plt.scatter(x_values, y_values)\n",
    "            plt.show()\n",
    "            # Get the average pixel color at these points\n",
    "            avg_pixel = np.mean([img[y, x] for x, y in zip(x_values, y_values)], axis=0)\n",
    "            print(avg_pixel)\n",
    "            shrunken_contour = cv2.approxPolyDP(contour, 0.1 * cv2.arcLength(contour, True), True)\n",
    "            avg_pixel = np.mean([img[y, x] for x, y in shrunken_contour[:, 0]], axis=0)\n",
    "            print(avg_pixel)\n",
    "            # return (img[y, x] == [0, 0, 0]).all()\n",
    "            return True\n",
    "        def contour_in_another_contour(contour, contours):\n",
    "            for other_contour in contours:\n",
    "                contour = contour.reshape((-1, 1, 2)).astype(np.int32)\n",
    "                other_contour = other_contour.reshape((-1, 1, 2)).astype(np.int32)\n",
    "                if cv2.pointPolygonTest(other_contour, (round(contour[0][0][0]), round(contour[0][0][1])), False) > 0:\n",
    "                    return True\n",
    "            return False\n",
    "        contours = [contour for contour in contours if not contour_in_another_contour(contour, contours)]\n",
    "        if display:\n",
    "            show_image(draw_contours(img, contours))\n",
    "        return len(contours)\n",
    "    \n",
    "    # get the average number of shapes in the first 8 images\n",
    "    num_shapes = [get_num_shapes(img, False) for img in images[:8]]\n",
    "    return np.mean(num_shapes)\n",
    "\n",
    "print(get_rule_type(iq_test_to_squares(get_image('iq_images/iq10.png')))) # expected 1\n",
    "print(get_rule_type(iq_test_to_squares(get_image('iq_images/iq16.png')))) # expected 1\n",
    "print(get_rule_type(iq_test_to_squares(get_image('iq_images/iq17.png')))) # expected 1\n",
    "print(get_rule_type(iq_test_to_squares(get_image('iq_images/iq09.png')))) # expected > 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_panorama(image1, image2):\n",
    "    \n",
    "    # Initialize the feature detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect features and compute descriptors\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2, None)\n",
    "\n",
    "    # Match features\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Filter matches using the Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches])\n",
    "    points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "    # Find homography\n",
    "    H, _ = cv2.findHomography(points2, points1, cv2.RANSAC)\n",
    "\n",
    "    # Warp images\n",
    "    height, width, channels = image1.shape\n",
    "    result = cv2.warpPerspective(image2, H, (width * 2, height))\n",
    "\n",
    "    # Copy image1 onto the panorama\n",
    "    result[0:image1.shape[0], 0:image1.shape[1]] = image1\n",
    "    return result\n",
    "\n",
    "# try it out\n",
    "circles_rotating = iq_test_to_squares(get_image('iq_images/iq16.png'))\n",
    "img1 = circles_rotating[0]\n",
    "img2 = circles_rotating[1]\n",
    "show_image(img1)\n",
    "show_image(img2)\n",
    "show_image(merge_panorama(img1, img2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
